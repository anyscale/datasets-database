{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![Ray Databricks Connector](../images/databrick_connector_logo.png)\n",
    "This user guide walks through the basics of reading and writing data with Ray and Databricks.\n",
    "\n",
    "The Ray Databricks connector enables parallel read and write to and from a Databricks SQL endpoint. The connector utilizes the Python DB API 2.0 specification implemented by most the Python Databricks Connect library.\n",
    "\n",
    "## Initialize ray\n",
    "Ray will automatically be initialized with defaults when calling any ray or ray dataset methods. To specify configuration, add the below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 21:05:16,756\tINFO worker.py:1242 -- Using address localhost:9031 set in the environment variable RAY_ADDRESS\n",
      "find: ‘.git’: No such file or directory\n",
      "2023-02-27 21:05:17,074\tINFO worker.py:1360 -- Connecting to existing Ray cluster at address: 10.0.36.75:9031...\n",
      "2023-02-27 21:05:17,081\tINFO worker.py:1548 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttps://console.anyscale.com/api/v2/sessions/ses_vnmb5jgl4z6q98h61dx25rccju/services?redirect_to=dashboard \u001b[39m\u001b[22m\n",
      "2023-02-27 21:05:17,084\tINFO packaging.py:330 -- Pushing file package 'gcs://_ray_pkg_de75729c0244af0b2679b245ffd05193.zip' (0.26MiB) to Ray cluster...\n",
      "2023-02-27 21:05:17,087\tINFO packaging.py:343 -- Successfully pushed file package 'gcs://_ray_pkg_de75729c0244af0b2679b245ffd05193.zip'.\n"
     ]
    }
   ],
   "source": [
    "import ray, logging\n",
    "logging.basicConfig(level=logging.ERROR) # only show errors\n",
    "\n",
    "if not ray.is_initialized():\n",
    "    ray.init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection properties\n",
    "The databricks  connection properties need to be provided to the data source upon creation. These properties are documented by the databricks.\n",
    "\n",
    "Below is an example of loading properties from the environment, and filtering them by the 'DATABRICKS_' prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection properties:\n",
      "catalog\n",
      "schema\n",
      "server_hostname\n",
      "access_token\n",
      "http_path\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "connect_props = {\n",
    "    key.replace('DATABRICKS_','').lower(): value \n",
    "    for key,value in os.environ.items() if 'DATABRICKS_' in key\n",
    "}\n",
    "\n",
    "# add db and schema in connect props\n",
    "connect_props = dict(\n",
    "    catalog = 'samples',\n",
    "    schema = 'tpch',\n",
    "    **connect_props\n",
    ")\n",
    "\n",
    "print('Connection properties:')\n",
    "print('\\n'.join(connect_props.keys()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading\n",
    "Ray will use Databricks Python API to read in parallel into a Ray cluster. The created Ray datasets is composed of PyArrow dataframes that are spread across the Ray cluster to allow for the distributed operations required in machine learning.\n",
    "\n",
    "![Databricks Read](../images/databricks_read.png)\n",
    "\n",
    "### Read from tables\n",
    "In order to read an entire table into a a Ray cluster, utilize the Ray data `read_databricks` method. The code below will read in a sample table from a Databricks sample database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read progress: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_custkey</th>\n",
       "      <th>c_name</th>\n",
       "      <th>c_address</th>\n",
       "      <th>c_nationkey</th>\n",
       "      <th>c_phone</th>\n",
       "      <th>c_acctbal</th>\n",
       "      <th>c_mktsegment</th>\n",
       "      <th>c_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>412445</td>\n",
       "      <td>Customer#000412445</td>\n",
       "      <td>0QAB3OjYnbP6mA0B,kgf</td>\n",
       "      <td>21</td>\n",
       "      <td>31-421-403-4333</td>\n",
       "      <td>5358.33</td>\n",
       "      <td>BUILDING</td>\n",
       "      <td>arefully blithely regular epi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>412446</td>\n",
       "      <td>Customer#000412446</td>\n",
       "      <td>5u8MSbyiC7J,7PuY4Ivaq1JRbTCMKeNVqg</td>\n",
       "      <td>20</td>\n",
       "      <td>30-487-949-7942</td>\n",
       "      <td>9441.59</td>\n",
       "      <td>MACHINERY</td>\n",
       "      <td>sleep according to the fluffily even forges. f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>412447</td>\n",
       "      <td>Customer#000412447</td>\n",
       "      <td>HC4ZT62gKPgrjr ceoaZgFOunlUogr7GO</td>\n",
       "      <td>7</td>\n",
       "      <td>17-797-466-6308</td>\n",
       "      <td>7868.75</td>\n",
       "      <td>AUTOMOBILE</td>\n",
       "      <td>aggle blithely among the carefully express excus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c_custkey              c_name                            c_address  \\\n",
       "0     412445  Customer#000412445                 0QAB3OjYnbP6mA0B,kgf   \n",
       "1     412446  Customer#000412446  5u8MSbyiC7J,7PuY4Ivaq1JRbTCMKeNVqg    \n",
       "2     412447  Customer#000412447    HC4ZT62gKPgrjr ceoaZgFOunlUogr7GO   \n",
       "\n",
       "   c_nationkey          c_phone c_acctbal c_mktsegment  \\\n",
       "0           21  31-421-403-4333   5358.33     BUILDING   \n",
       "1           20  30-487-949-7942   9441.59    MACHINERY   \n",
       "2            7  17-797-466-6308   7868.75   AUTOMOBILE   \n",
       "\n",
       "                                           c_comment  \n",
       "0                      arefully blithely regular epi  \n",
       "1  sleep according to the fluffily even forges. f...  \n",
       "2   aggle blithely among the carefully express excus  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.data import read_databricks\n",
    "\n",
    "# read the table, limiting to first 1K customers\n",
    "ds = read_databricks(connect_props, table='customer').limit(10)\n",
    "\n",
    "# display the first 3 results\n",
    "ds.limit(3).to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read with a query\n",
    "For more control over columns and rows read, as well as joining data from multiple tables, a query can be specified instead of a table name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read progress: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_ACCTBAL</th>\n",
       "      <th>C_MKTSEGMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-219.53</td>\n",
       "      <td>BUILDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-778.23</td>\n",
       "      <td>AUTOMOBILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-848.16</td>\n",
       "      <td>BUILDING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  C_ACCTBAL C_MKTSEGMENT\n",
       "0   -219.53     BUILDING\n",
       "1   -778.23   AUTOMOBILE\n",
       "2   -848.16     BUILDING"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY = 'SELECT C_ACCTBAL, C_MKTSEGMENT FROM CUSTOMER WHERE C_ACCTBAL < 0 LIMIT 1000'\n",
    "\n",
    "# read the result of the query\n",
    "ds2 = read_databricks(connect_props, query=QUERY)\n",
    "\n",
    "# display the first 3 results\n",
    "ds2.limit(3).to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional read parameters\n",
    "For reading from Databricks, underlying Python API arguments are also available and can be passed to the underlying execute method.\n",
    "\n",
    "The code below uses the parameters argument to specify parameterss to be used by Databricks when executing the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read progress: 100%|██████████| 1/1 [00:00<00:00,  4.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_ACCTBAL</th>\n",
       "      <th>C_MKTSEGMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5358.33</td>\n",
       "      <td>BUILDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9441.59</td>\n",
       "      <td>MACHINERY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7868.75</td>\n",
       "      <td>AUTOMOBILE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  C_ACCTBAL C_MKTSEGMENT\n",
       "0   5358.33     BUILDING\n",
       "1   9441.59    MACHINERY\n",
       "2   7868.75   AUTOMOBILE"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY = 'SELECT C_ACCTBAL, C_MKTSEGMENT FROM CUSTOMER WHERE C_ACCTBAL > %(balance)i LIMIT 100'\n",
    "\n",
    "ds3 = read_databricks(connect_props, query=QUERY, parameters={'balance':2.0})\n",
    "ds3.limit(3).to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing\n",
    "The Ray Databricks connector will use the Databricks driver to write each partition of data in parallel. Each partition of data in the Ray dataset will have a write task that writes in parallel to a cload strorage location. After the \n",
    "partitions are written, a table is created using the parquet files. This \n",
    "![Databricks write](../images/databricks_write.png)\n",
    "\n",
    "### Configure a metastore\n",
    "Prior to running this code, a storage bucket that is accessible to the Ray cluster and Databricks needs to be confgured. To add a storage location into the Unity catalog, follow these [instructions](https://docs.databricks.com/data-governance/unity-catalog/get-started.html#cloud-tenant-setup-aws). You will need administrative privledges to your cloud account. \n",
    "\n",
    "Since data will be written to Databricks, a metastore with create table and write permissions for your user must also exist. To create a metastore, follow these [instructions](https://docs.databricks.com/data-governance/unity-catalog/create-metastore.html). You will need administrative privledges to Databricks.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.sql import connect\n",
    "\n",
    "write_connect_props = {\n",
    "    **connect_props, \n",
    "    'catalog':'hive_metastore',\n",
    "    'schema':'default'\n",
    "}\n",
    "\n",
    "# create destination table\n",
    "with connect(**write_connect_props) as con:\n",
    "    with con.cursor() as cursor:\n",
    "        cursor.execute('DROP TABLE IF EXISTS customer2')\n",
    "        #cursor.execute('CREATE TABLE customer2 USING DELTA AS (SELECT * FROM samples.tpch.customer LIMIT 0)')\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to tables\n",
    "In order to write a dataset into database table, use the `write_databricks` method of the dataset object. Repartition the dataset prior to calling this method in order to set the number of write tasks.\n",
    "\n",
    "The example below writes the previously read data into a new database table that are created using the Snowflake Python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 21:05:31,905\tWARNING plan.py:528 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune\n",
      "2023-02-27 21:05:31,909\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[write]\n",
      "write: 100%|██████████| 1/1 [00:14<00:00, 14.76s/it]\n",
      "2023-02-27 21:05:46,692\tINFO bulk_executor.py:41 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[write]\n",
      "write: 100%|██████████| 1/1 [00:03<00:00,  3.73s/it]\n",
      "Read progress: 100%|██████████| 3/3 [00:04<00:00,  1.49s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_custkey</th>\n",
       "      <th>c_name</th>\n",
       "      <th>c_address</th>\n",
       "      <th>c_nationkey</th>\n",
       "      <th>c_phone</th>\n",
       "      <th>c_acctbal</th>\n",
       "      <th>c_mktsegment</th>\n",
       "      <th>c_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>412445</td>\n",
       "      <td>Customer#000412445</td>\n",
       "      <td>0QAB3OjYnbP6mA0B,kgf</td>\n",
       "      <td>21</td>\n",
       "      <td>31-421-403-4333</td>\n",
       "      <td>5358.33</td>\n",
       "      <td>BUILDING</td>\n",
       "      <td>arefully blithely regular epi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>412446</td>\n",
       "      <td>Customer#000412446</td>\n",
       "      <td>5u8MSbyiC7J,7PuY4Ivaq1JRbTCMKeNVqg</td>\n",
       "      <td>20</td>\n",
       "      <td>30-487-949-7942</td>\n",
       "      <td>9441.59</td>\n",
       "      <td>MACHINERY</td>\n",
       "      <td>sleep according to the fluffily even forges. f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>412447</td>\n",
       "      <td>Customer#000412447</td>\n",
       "      <td>HC4ZT62gKPgrjr ceoaZgFOunlUogr7GO</td>\n",
       "      <td>7</td>\n",
       "      <td>17-797-466-6308</td>\n",
       "      <td>7868.75</td>\n",
       "      <td>AUTOMOBILE</td>\n",
       "      <td>aggle blithely among the carefully express excus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c_custkey              c_name                            c_address  \\\n",
       "0     412445  Customer#000412445                 0QAB3OjYnbP6mA0B,kgf   \n",
       "1     412446  Customer#000412446  5u8MSbyiC7J,7PuY4Ivaq1JRbTCMKeNVqg    \n",
       "2     412447  Customer#000412447    HC4ZT62gKPgrjr ceoaZgFOunlUogr7GO   \n",
       "\n",
       "   c_nationkey          c_phone c_acctbal c_mktsegment  \\\n",
       "0           21  31-421-403-4333   5358.33     BUILDING   \n",
       "1           20  30-487-949-7942   9441.59    MACHINERY   \n",
       "2            7  17-797-466-6308   7868.75   AUTOMOBILE   \n",
       "\n",
       "                                           c_comment  \n",
       "0                      arefully blithely regular epi  \n",
       "1  sleep according to the fluffily even forges. f...  \n",
       "2   aggle blithely among the carefully express excus  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write the dataset to the table \n",
    "ds.write_databricks(\n",
    "    write_connect_props, \n",
    "    table='hive_metastore.default.customer2',\n",
    "    stage_uri='s3://egr-sydney-databricks/stage'\n",
    ")\n",
    "\n",
    "# read the new table\n",
    "ds4 = read_databricks(write_connect_props, table='customer2')\n",
    "ds4.limit(3).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage\n",
    "If more low level access to the Ray Databricks connector is needed, the underlying `DatabricksConnector` and `DatabricksDatasource` can be used.\n",
    "\n",
    "### Databricks Connector\n",
    "The `DatabricksConnector` class holds the connection properties and logic required to establish a connection with Databricks. Internally it calls the native Python dirver API in order to read and write from and to tables in parallel across the cluster. The datasource uses the DB API 2 `execute` and `executemany` methods to enable parallel read and writes of data.\n",
    "\n",
    "The connector is also a Python context manager, and utilize `with` semantics to define when a connection should be established, db operations commited to the database, and the connection closed. \n",
    "\n",
    "The code below will read from a sample table using the connector to manage the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750000\n"
     ]
    }
   ],
   "source": [
    "from ray.data.datasource import DatabricksConnector\n",
    "\n",
    "# query the number of rows, using the connection context to\n",
    "# manage transactions\n",
    "with DatabricksConnector(**connect_props) as connector:\n",
    "    count = connector.query_int(f'SELECT COUNT(*) FROM customer')\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use `try` blocks with the connector's `open`, `commit` and `close` methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    connector = DatabricksConnector(**write_connect_props)\n",
    "    connector.open()\n",
    "    count = connector.query_int(f'SELECT COUNT(*) FROM customer2')\n",
    "finally:\n",
    "    connector.close()\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Databricks Datasource\n",
    "The Databricks datasource can be used with the Ray data `read_datasource` and `write_datasource` methods to read and write to databases using the distibuted processing capabilities of Ray data. The datasource uses the DatabricksConnector class internally.\n",
    "\n",
    "Below is an example of creating the datasource using the previously defined connect properties, and then using it to read and write."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read progress: 100%|██████████| 3/3 [00:00<00:00,  8.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_custkey</th>\n",
       "      <th>c_name</th>\n",
       "      <th>c_address</th>\n",
       "      <th>c_nationkey</th>\n",
       "      <th>c_phone</th>\n",
       "      <th>c_acctbal</th>\n",
       "      <th>c_mktsegment</th>\n",
       "      <th>c_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>412445</td>\n",
       "      <td>Customer#000412445</td>\n",
       "      <td>0QAB3OjYnbP6mA0B,kgf</td>\n",
       "      <td>21</td>\n",
       "      <td>31-421-403-4333</td>\n",
       "      <td>5358.33</td>\n",
       "      <td>BUILDING</td>\n",
       "      <td>arefully blithely regular epi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>412446</td>\n",
       "      <td>Customer#000412446</td>\n",
       "      <td>5u8MSbyiC7J,7PuY4Ivaq1JRbTCMKeNVqg</td>\n",
       "      <td>20</td>\n",
       "      <td>30-487-949-7942</td>\n",
       "      <td>9441.59</td>\n",
       "      <td>MACHINERY</td>\n",
       "      <td>sleep according to the fluffily even forges. f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>412447</td>\n",
       "      <td>Customer#000412447</td>\n",
       "      <td>HC4ZT62gKPgrjr ceoaZgFOunlUogr7GO</td>\n",
       "      <td>7</td>\n",
       "      <td>17-797-466-6308</td>\n",
       "      <td>7868.75</td>\n",
       "      <td>AUTOMOBILE</td>\n",
       "      <td>aggle blithely among the carefully express excus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c_custkey              c_name                            c_address  \\\n",
       "0     412445  Customer#000412445                 0QAB3OjYnbP6mA0B,kgf   \n",
       "1     412446  Customer#000412446  5u8MSbyiC7J,7PuY4Ivaq1JRbTCMKeNVqg    \n",
       "2     412447  Customer#000412447    HC4ZT62gKPgrjr ceoaZgFOunlUogr7GO   \n",
       "\n",
       "   c_nationkey          c_phone c_acctbal c_mktsegment  \\\n",
       "0           21  31-421-403-4333   5358.33     BUILDING   \n",
       "1           20  30-487-949-7942   9441.59    MACHINERY   \n",
       "2            7  17-797-466-6308   7868.75   AUTOMOBILE   \n",
       "\n",
       "                                           c_comment  \n",
       "0                      arefully blithely regular epi  \n",
       "1  sleep according to the fluffily even forges. f...  \n",
       "2   aggle blithely among the carefully express excus  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.data.datasource import DatabricksDatasource\n",
    "from ray.data import read_datasource\n",
    "\n",
    "# create a datasource from a connector\n",
    "datasource = DatabricksDatasource(connector)\n",
    "\n",
    "# use read_datasource to read\n",
    "ds = read_datasource(datasource, table='customer2')\n",
    "ds.limit(3).to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DML and DDL\n",
    "The connector can also be used for any DDL or DML operations you would normally execute through the DB Native Python API. These operations just pass through to the underlying API. \n",
    "\n",
    "The code below will create the objects needed for writing to tables. Note that a commit is issued between the queries so the DDL operation executes prior to the next one that is dependent. An alternative is to use two `with` blocks to define transaction boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with connector as con:\n",
    "    con.query('DROP TABLE IF EXISTS customer2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5abf9a257024fa0ae177d32ddc0977bda32aa95f4f2d5d07f829679a9e9e7642"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
